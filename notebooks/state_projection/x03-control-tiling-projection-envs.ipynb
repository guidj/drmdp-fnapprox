{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96def89d-da64-421c-9fa7-4e7c383cac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from typing import Any, Sequence, Mapping, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294d273e-aa6e-40b5-9cd3-e44c87415250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of fitting a gaussian mixture model with expectation maximization\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "from scipy import stats\n",
    "from scipy import linalg\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bc1d62-7fa9-495e-877d-909c4f7fa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlplg.environments import gridworld, iceworld, redgreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40d14be-fe4e-45da-95ed-2ef2504f5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7db704-00b1-4cbc-9384-3c343c25365e",
   "metadata": {},
   "source": [
    "## Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d5c2a4-810f-4e6d-becb-913237eee752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tile Coding Software version 3.0beta\n",
    "by Rich Sutton\n",
    "based on a program created by Steph Schaeffer and others\n",
    "External documentation and recommendations on the use of this code is available in the \n",
    "reinforcement learning textbook by Sutton and Barto, and on the web.\n",
    "These need to be understood before this code is.\n",
    "\n",
    "This software is for Python 3 or more.\n",
    "\n",
    "This is an implementation of grid-style tile codings, based originally on\n",
    "the UNH CMAC code (see http://www.ece.unh.edu/robots/cmac.htm), but by now highly changed. \n",
    "Here we provide a function, \"tiles\", that maps floating and integer\n",
    "variables to a list of tiles, and a second function \"tiles-wrap\" that does the same while\n",
    "wrapping some floats to provided widths (the lower wrap value is always 0).\n",
    "\n",
    "The float variables will be gridded at unit intervals, so generalization\n",
    "will be by approximately 1 in each direction, and any scaling will have \n",
    "to be done externally before calling tiles.\n",
    "\n",
    "Num-tilings should be a power of 2, e.g., 16. To make the offsetting work properly, it should\n",
    "also be greater than or equal to four times the number of floats.\n",
    "\n",
    "The first argument is either an index hash table of a given size (created by (make-iht size)), \n",
    "an integer \"size\" (range of the indices from 0), or nil (for testing, indicating that the tile \n",
    "coordinates are to be returned without being converted to indices).\n",
    "\"\"\"\n",
    "\n",
    "basehash = hash\n",
    "\n",
    "class IHT:\n",
    "    \"Structure to handle collisions\"\n",
    "    def __init__(self, sizeval):\n",
    "        self.size = sizeval                        \n",
    "        self.overfullCount = 0\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        \"Prepares a string for printing whenever this object is printed\"\n",
    "        return \"Collision table:\" + \\\n",
    "               \" size:\" + str(self.size) + \\\n",
    "               \" overfullCount:\" + str(self.overfullCount) + \\\n",
    "               \" dictionary:\" + str(len(self.dictionary)) + \" items\"\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.dictionary)\n",
    "    \n",
    "    def fullp(self):\n",
    "        return len(self.dictionary) >= self.size\n",
    "    \n",
    "    def getindex(self, obj, readonly=False):\n",
    "        d = self.dictionary\n",
    "        if obj in d: return d[obj]\n",
    "        elif readonly: return None\n",
    "        size = self.size\n",
    "        count = self.count()\n",
    "        if count >= size:\n",
    "            # TODO: Fail\n",
    "            if self.overfullCount==0: print('IHT full, starting to allow collisions')\n",
    "            self.overfullCount += 1\n",
    "            return basehash(obj) % self.size\n",
    "        else:\n",
    "            d[obj] = count\n",
    "            return count\n",
    "\n",
    "def hashcoords(coordinates, m, readonly=False):\n",
    "    if type(m)==IHT: return m.getindex(tuple(coordinates), readonly)\n",
    "    if type(m)==int: return basehash(tuple(coordinates)) % m\n",
    "    if m==None: return coordinates\n",
    "\n",
    "from math import floor, log\n",
    "from itertools import zip_longest\n",
    "\n",
    "def tiles (ihtORsize, numtilings, floats, ints=[], readonly=False):\n",
    "    \"\"\"returns num-tilings tile indices corresponding to the floats and ints\"\"\"\n",
    "    qfloats = [floor(f*numtilings) for f in floats]\n",
    "    Tiles = []\n",
    "    for tiling in range(numtilings):\n",
    "        tilingX2 = tiling*2\n",
    "        coords = [tiling]\n",
    "        b = tiling\n",
    "        for q in qfloats:\n",
    "            coords.append( (q + b) // numtilings )\n",
    "            b += tilingX2\n",
    "        coords.extend(ints)\n",
    "        Tiles.append(hashcoords(coords, ihtORsize, readonly))\n",
    "    return Tiles\n",
    "\n",
    "def tileswrap (ihtORsize, numtilings, floats, wrapwidths, ints=[], readonly=False):\n",
    "    \"\"\"returns num-tilings tile indices corresponding to the floats and ints, wrapping some floats\"\"\"\n",
    "    qfloats = [floor(f*numtilings) for f in floats]\n",
    "    Tiles = []\n",
    "    for tiling in range(numtilings):\n",
    "        tilingX2 = tiling*2\n",
    "        coords = [tiling]\n",
    "        b = tiling\n",
    "        for q, width in zip_longest(qfloats, wrapwidths):\n",
    "            c = (q + b%numtilings) // numtilings\n",
    "            coords.append(c%width if width else c)\n",
    "            b += tilingX2\n",
    "        coords.extend(ints)\n",
    "        Tiles.append(hashcoords(coords, ihtORsize, readonly))\n",
    "    return Tiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4b462b-7268-4386-93ab-a66b97a7f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow2geq(lb):\n",
    "    exp = 1\n",
    "    while True:\n",
    "        rs = np.power(2, exp)\n",
    "        if rs >= lb:\n",
    "            break\n",
    "        exp += 1\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afda79b6-d5b8-4d37-b25f-62b6fe11b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_least_squares(\n",
    "    matrix: np.ndarray, rhs: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    try:\n",
    "        solution, _, _, _ = linalg.lstsq(a=matrix, b=rhs, lapack_driver=\"gelsy\")\n",
    "        return solution  # type: ignore\n",
    "    except linalg.LinAlgError as err:\n",
    "        # the computation failed, likely due to the matix being unsuitable (no solution).\n",
    "        raise ValueError(\"Failed to solve linear system\") from err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d6e2d2-d01d-4507-9d37-51d09d9ef9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(v_pred: np.ndarray, v_true: np.ndarray, axis: int):\n",
    "    if np.shape(v_pred) != np.shape(v_true):\n",
    "        raise ValueError(\n",
    "            f\"Tensors have different shapes: {np.shape(v_pred)} != {np.shape(v_true)}\"\n",
    "        )\n",
    "    return np.sqrt(\n",
    "        np.sum(np.power(v_pred - v_true, 2.0), axis=axis) / np.shape(v_pred)[axis]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac3c0c3-7c24-45bb-84b7-c33a282af342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiles:\n",
    "    def __init__(\n",
    "        self, dims_min: np.ndarray, dims_max: np.ndarray, \n",
    "        tiling_dim: int, num_tilings: Optional[int] = None\n",
    "    ):\n",
    "        assert isinstance(dims_min, np.ndarray)\n",
    "        assert isinstance(dims_max, np.ndarray)\n",
    "        self.dims_max = dims_max\n",
    "        self.dims_min = dims_min\n",
    "        self.tiling_dim = tiling_dim\n",
    "        self.wrapwidths = [tiling_dim] * np.size(dims_min)\n",
    "    \n",
    "        # num tilings should a power of 2\n",
    "        # and at least 4 times greater than\n",
    "        # the number of dimensions\n",
    "        self.num_tilings = num_tilings or pow2geq(np.size(dims_min) * 4)\n",
    "        self.max_size = (tiling_dim ** np.size(dims_min)) * self.num_tilings\n",
    "        print(\"Num tilings\", self.num_tilings, \"\\n\", \"Flat dim:\", self.max_size)\n",
    "        self.iht = IHT(self.max_size)\n",
    "\n",
    "    def __call__(self, xs):\n",
    "        xs_scaled_01 = (xs - self.dims_min) / (self.dims_max - self.dims_min)\n",
    "        repr = np.zeros(shape=self.max_size)\n",
    "        idx = tileswrap(\n",
    "            self.iht, \n",
    "            self.num_tilings, \n",
    "            xs_scaled_01 * self.tiling_dim,\n",
    "            self.wrapwidths\n",
    "        )\n",
    "        repr[idx] = 1\n",
    "        return repr    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c34679-56cc-4d1d-8472-5c02a3606bd9",
   "metadata": {},
   "source": [
    "## Control with SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be069c80-71ce-4f52-9aa8-119fd57fe246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_traj_data(env, steps: int):\n",
    "    obs, _ = env.reset()\n",
    "    step = 0\n",
    "    buffer = []\n",
    "    while step < steps:\n",
    "        action = env.action_space.sample()\n",
    "        next_obs, rew, term, trunc, _,  = env.step(action)\n",
    "        step += 1\n",
    "        buffer.append((obs, action, rew))\n",
    "        obs = next_obs\n",
    "        if term or trunc:\n",
    "            obs, _ = env.reset()\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e9b2e4-1ef5-45ee-ae06-869452940499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_reward_data(buffer, delay: int, sample_size: int):\n",
    "    obs = np.stack([example[0] for example in buffer])\n",
    "    action = np.stack([example[1] for example in buffer])\n",
    "    reward = np.stack([example[2] for example in buffer])\n",
    "\n",
    "    # repr: (m1,a1)(m2,a1)..\n",
    "    mdim = obs.shape[1] * len(np.unique(action))\n",
    "    num_components = obs.shape[1]\n",
    "\n",
    "    # build samples\n",
    "    mask = np.random.choice(len(obs), (sample_size, delay))\n",
    "    delayed_obs = obs[mask] # batch x delay x dim\n",
    "    delayed_act = action[mask]\n",
    "    delayed_rew = np.sum(reward[mask], axis=1) # batch x delay -> batch    \n",
    "    \n",
    "    rhat_matrix = np.zeros(shape=(len(delayed_obs), mdim))\n",
    "    \n",
    "    for i in range(len(delayed_obs)):\n",
    "        for j in range(delay):\n",
    "            c = num_components*delayed_act[i][j]\n",
    "            rhat_matrix[i,c:c+num_components] += delayed_obs[i][j]\n",
    "\n",
    "    return rhat_matrix, delayed_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f3b2ea-8920-4cbf-b60a-dc7282781da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_obs_to_rwest_vec(buffer, sample_size: int):\n",
    "    obs = np.stack([example[0] for example in buffer])\n",
    "    action = np.stack([example[1] for example in buffer])\n",
    "    reward = np.stack([example[2] for example in buffer])\n",
    "    \n",
    "    # repr: (m1,a1)(m2,a1)..\n",
    "    mdim = obs.shape[1] * len(np.unique(action))\n",
    "    num_components = obs.shape[1]\n",
    "\n",
    "    # build samples\n",
    "    mask = np.random.choice(len(obs), sample_size)\n",
    "    delayed_obs = obs[mask] # batch x dim\n",
    "    delayed_act = action[mask] # batch\n",
    "    delayed_rew = reward[mask] # batch\n",
    "    \n",
    "    rhat_matrix = np.zeros(shape=(len(delayed_obs), mdim))\n",
    "    \n",
    "    for i in range(len(delayed_obs)):\n",
    "        c = num_components*delayed_act[i]\n",
    "        rhat_matrix[i,c:c+num_components] += delayed_obs[i]\n",
    "    return rhat_matrix, delayed_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c02d574b-b801-47c0-bd4b-97a549aebbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_rwe(env: gym.Env, num_steps: int, sample_size: int, delay: int):\n",
    "    buffer = collection_traj_data(env, steps=num_steps)\n",
    "    Xd, yd = delay_reward_data(buffer, delay=delay, sample_size=sample_size)\n",
    "    return buffer, solve_least_squares(Xd, yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb51c96-dd50-4120-bba8-5c8b79dbe937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rwe_scatterplot(v_pred, v_true):\n",
    "    _, ax = plt.subplots(figsize=(6, 6))\n",
    "    df = pd.DataFrame({\n",
    "        \"x\": v_pred,\n",
    "        \"y\": v_true,\n",
    "        \"size\": np.abs(v_pred - v_true)\n",
    "    })\n",
    "    sns.scatterplot(\n",
    "        df, x=\"x\", y=\"y\", size=\"size\", hue=\"size\", s=5, color=\".15\"\n",
    "    )\n",
    "    ax.set_xlabel(\"yhat\")\n",
    "    ax.set_ylabel(\"ytrue\")\n",
    "    ax.set_title(\"Reward Estimation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b71c921-f5eb-45a9-9f90-40541af19038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtrick(xs, dim: int):\n",
    "    ys = np.zeros(dim, dtype=np.int32)\n",
    "    idx,  = np.where(xs == 1)\n",
    "    for i in idx:\n",
    "        ys[i % dim] += 1\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3008-492e-4fb1-adde-b63b0b956440",
   "metadata": {},
   "source": [
    "### Moutain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "259707b8-d7a0-4522-a816-b45bbd6c3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCObsWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, tiling_dim: int, num_tilings: int = None):\n",
    "        super().__init__(env)\n",
    "        self.tiles = Tiles(\n",
    "                env.observation_space.low,\n",
    "                env.observation_space.high,\n",
    "                tiling_dim=tiling_dim,\n",
    "                num_tilings=num_tilings\n",
    "            )\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.zeros(shape=self.tiles.max_size, dtype=np.int32), \n",
    "            high=np.ones(shape=self.tiles.max_size, dtype=np.int32)\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return self.tiles(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cac9ed1-0984-404c-bf43-e5abf82b9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tilings 8 \n",
      " Flat dim: 512\n"
     ]
    }
   ],
   "source": [
    "env = MCObsWrapper(\n",
    "    env=gym.make(\"MountainCar-v0\", max_episode_steps=10000), \n",
    "    tiling_dim=8\n",
    ")\n",
    "\n",
    "def feat_transform(obs, actions: Sequence[int]):\n",
    "    num_actions = len(actions)\n",
    "    dim = obs.shape[0] * num_actions\n",
    "    state_action_m = np.zeros(shape=(num_actions, dim))\n",
    "\n",
    "    for idx, action in enumerate(actions):\n",
    "        s_col = obs.shape[0] * action\n",
    "        state_action_m[idx, s_col:s_col+obs.shape[0]] += obs\n",
    "    return state_action_m\n",
    "\n",
    "\n",
    "def action_values(obs, actions: Sequence[int], weights):\n",
    "    state_action_m = feat_transform(obs, actions)\n",
    "    return np.dot(state_action_m, weights)\n",
    "\n",
    "# TODO: unify values and gradient fn (one call for both)\n",
    "def semi_gradient_sarsa(env, alpha: float, gamma: float, epsilon: float, num_episodes: int):\n",
    "    actions = tuple(range(env.action_space.n))\n",
    "    weights = np.zeros(env.observation_space.shape[0] * len(actions), dtype=np.float64)\n",
    "    returns = []\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        state_qvalues = action_values(obs, actions, weights)\n",
    "        gradients = feat_transform(obs, actions)\n",
    "        rewards = 0\n",
    "        # choose action\n",
    "        if random.random() <= epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.random.choice(np.flatnonzero(state_qvalues == state_qvalues.max()))\n",
    "\n",
    "        while True:\n",
    "            # greedy            \n",
    "            next_obs, reward, term, trunc, _,  = env.step(action)\n",
    "            rewards += reward\n",
    "            \n",
    "            if term or trunc:\n",
    "                weights = weights + alpha * (reward - state_qvalues[action]) * gradients[action]\n",
    "                break\n",
    "\n",
    "            next_state_qvalues = action_values(next_obs, actions, weights)\n",
    "            next_gradients = feat_transform(next_obs, actions)\n",
    "            \n",
    "            if random.random() <= epsilon:\n",
    "                next_action = env.action_space.sample()\n",
    "            else:\n",
    "                # greedy\n",
    "                next_action = np.random.choice(np.flatnonzero(next_state_qvalues == next_state_qvalues.max()))\n",
    "\n",
    "            weights = weights + alpha * (\n",
    "                reward + gamma * next_state_qvalues[next_action] - state_qvalues[action]\n",
    "            ) * gradients[action]\n",
    "            obs = next_obs\n",
    "            action = next_action\n",
    "            state_qvalues = next_state_qvalues\n",
    "            gradients = next_gradients\n",
    "        returns.append(rewards)\n",
    "        if i % 200 == 0:\n",
    "            print(\"Episode\", i, \"mean returns:\", np.mean(returns[-100:]))\n",
    "    return weights\n",
    "\n",
    "\n",
    "def play(env, weights, num_episodes: int):\n",
    "    actions = tuple(range(env.action_space.n))\n",
    "    for i in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        rewards = 0\n",
    "        print(\"Playing ep\", i + 1)\n",
    "        while True:\n",
    "            state_qvalues = action_values(obs, actions, weights)\n",
    "            action = np.random.choice(np.flatnonzero(state_qvalues == state_qvalues.max()))\n",
    "            next_obs, reward, term, trunc, _,  = env.step(action)\n",
    "            rewards += reward\n",
    "            obs = next_obs\n",
    "            if term or trunc:\n",
    "                print(\"Return\", rewards)\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9e62797-cf71-43d6-86ec-f337265d79da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 mean returns: -1230.0\n",
      "Episode 200 mean returns: -442.69\n",
      "Episode 400 mean returns: -597.56\n",
      "Episode 600 mean returns: -721.25\n",
      "Episode 800 mean returns: -721.01\n",
      "Episode 1000 mean returns: -1012.24\n",
      "Episode 1200 mean returns: -1176.92\n",
      "Episode 1400 mean returns: -692.92\n",
      "Episode 1600 mean returns: -775.17\n",
      "Episode 1800 mean returns: -735.27\n",
      "Episode 2000 mean returns: -1066.26\n",
      "Episode 2200 mean returns: -772.62\n",
      "Episode 2400 mean returns: -720.78\n",
      "Episode 2600 mean returns: -725.63\n",
      "Episode 2800 mean returns: -729.17\n",
      "Episode 3000 mean returns: -727.12\n",
      "Episode 3200 mean returns: -708.63\n",
      "Episode 3400 mean returns: -737.82\n",
      "Episode 3600 mean returns: -588.97\n",
      "Episode 3800 mean returns: -775.25\n",
      "Episode 4000 mean returns: -842.01\n",
      "Episode 4200 mean returns: -892.45\n",
      "Episode 4400 mean returns: -595.43\n",
      "Episode 4600 mean returns: -822.0\n",
      "Episode 4800 mean returns: -736.18\n",
      "Playing ep 1\n",
      "Return -276.0\n",
      "Playing ep 2\n",
      "Return -282.0\n",
      "Playing ep 3\n",
      "Return -265.0\n"
     ]
    }
   ],
   "source": [
    "weights = semi_gradient_sarsa(env, alpha=0.1, gamma=0.99, epsilon=0.2, num_episodes=5000)\n",
    "play(env, weights, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f11f06-29d3-4cb4-8c94-22a84c8a314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactors\n",
    "# 1. Introduce features processor for (S,A), initialised for an environment (can use tiles or gaussian, etc)\n",
    "# 2. Use replay generator - updates will apply at the end of an episode - consistently across algorithms\n",
    "# 3. Introduce Policy classs (with fn approx interface - updates can be done internally)\n",
    "# 4. Assess benefits of using torch for updates (computing gradients)\n",
    "# 5. zero impute\n",
    "# 6. options baseline - dynamic options\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
